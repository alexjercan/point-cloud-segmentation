{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efd993c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd7cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datachallengecode import load_data\n",
    "from datachallengecode import metric\n",
    "from pointnet import PointNet\n",
    "\n",
    "from torchmetrics import MeanMetric, Accuracy, F1Score\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de23af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    \"background\": 0,\n",
    "    \"beams\": 1,\n",
    "    \"cabletrays\": 2,\n",
    "    \"civils\": 3,\n",
    "    \"gratings\": 4,\n",
    "    \"guardrails\": 5,\n",
    "    \"hvac\": 6,\n",
    "    \"ladders\": 7,\n",
    "    \"piping\": 8,\n",
    "    \"supports\": 9,\n",
    "}\n",
    "\n",
    "n_classes = len(class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e799f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "\n",
    "ytrain_path = os.path.join(data_path, \"ytrain.csv\")\n",
    "xtrain_path = os.path.join(data_path, \"xtrain\")\n",
    "\n",
    "ytrain_map__path = os.path.join(data_path, \"ytrain_map_ind_station.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbaf9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlyPointsDataset(Dataset):\n",
    "    def __init__(self, data_path, station_id=0, cloud_size=2048, transform=None):\n",
    "        ytrain_path = os.path.join(data_path, \"ytrain.csv\")\n",
    "        xtrain_path = os.path.join(data_path, \"xtrain\")\n",
    "        ply_file = os.path.join(xtrain_path, f\"SCAN_{station_id}.ply\")\n",
    "\n",
    "        ytrain_map__path = os.path.join(data_path, \"ytrain_map_ind_station.csv\")\n",
    "        \n",
    "        _, x = load_data.read_x_plyfile(ply_file)\n",
    "        rest = cloud_size - (x.shape[0] % cloud_size)\n",
    "        x = np.concatenate([x, x[:rest, :]])\n",
    "        x[:, :3] = x[:, :3] / (x[:, :3].max() - x[:, :3].min())\n",
    "        x[:, 3:6] = x[:, 3:6] / 255\n",
    "        x[:, 6] = x[:, 6] / 255\n",
    "        self.x = x.reshape(-1, cloud_size, x.shape[-1]).transpose(0, 2, 1)\n",
    "\n",
    "        y_map = pd.read_csv(ytrain_map__path, header=None, names=[\"station_id\", \"point_id_low\", \"point_id_high\"])\n",
    "        y_map.set_index(\"station_id\", inplace=True)\n",
    "        low, high = y_map.loc[station_id]\n",
    "        y = pd.read_csv(ytrain_path)\n",
    "        y.set_index(\"ID\", inplace=True)\n",
    "        y = y.loc[low:high][\"class\"].to_numpy()\n",
    "        y = np.concatenate([y, y[:rest]])\n",
    "        self.y = y.reshape(-1, cloud_size)\n",
    "        \n",
    "        self.cloud_size = cloud_size\n",
    "        self.station_id = station_id\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = (self.x[idx], self.y[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "\n",
    "def transform(sample):\n",
    "    x, y = sample\n",
    "    \n",
    "    x = torch.from_numpy(x).to(DEVICE)\n",
    "    y = torch.from_numpy(y).to(DEVICE)\n",
    "    \n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90a65a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, dataloader, criterion):\n",
    "    mean = MeanMetric()\n",
    "    f1 = F1Score(num_classes=n_classes, mdmc_reduce=\"global\")\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(tqdm(eval_dataloader), 0):\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = net(inputs)\n",
    "            \n",
    "        preds = outputs.argmax(dim=1)\n",
    "        \n",
    "        loss = criterion(outputs, labels).item()\n",
    "        mean.update(loss)\n",
    "        f1.update(outputs, labels)\n",
    "        \n",
    "    return mean.compute(), f1.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa4dcf",
   "metadata": {},
   "source": [
    "## PointNet++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb0ed642",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PointNet(num_classes=n_classes).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6509f52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ids used for train are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 37, 38, 39, 40, 41, 42, 44, 45, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]\n"
     ]
    }
   ],
   "source": [
    "train_ply_ids = sorted(map(lambda path: int(pathlib.Path(path).stem.split(\"_\")[-1]), os.listdir(xtrain_path)))\n",
    "print(f\"The ids used for train are {train_ply_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d115502",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = PlyPointsDataset(data_path, station_id=66, transform=transform)\n",
    "\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ply_id: 0,    50] loss: 1.555\n",
      "[ply_id: 0,   100] loss: 1.072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d4abc59f364674b712f23377662e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ply_id: 66, eval] loss: 1.066 f1:  0.772\n",
      "[ply_id: 1,    50] loss: 1.226\n",
      "[ply_id: 1,   100] loss: 1.199\n",
      "[ply_id: 1,   150] loss: 1.181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917d0aad94fa406c94c2edc496357b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ply_id: 66, eval] loss: 0.951 f1:  0.772\n",
      "[ply_id: 2,    50] loss: 1.539\n",
      "[ply_id: 2,   100] loss: 1.400\n",
      "[ply_id: 2,   150] loss: 1.383\n",
      "[ply_id: 2,   200] loss: 1.375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8efa8344ffc42c7929fbef3ab3502d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ply_id: 66, eval] loss: 1.293 f1:  0.435\n",
      "[ply_id: 3,    50] loss: 1.443\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "eval_losses = []\n",
    "eval_f1s = []\n",
    "\n",
    "log_steps = 50\n",
    "mean = MeanMetric()\n",
    "for ply_id in train_ply_ids[:5]:\n",
    "    train_dataset = PlyPointsDataset(data_path, station_id=ply_id, transform=transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs, _ = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        mean.update(loss.item())\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % log_steps == log_steps-1:\n",
    "            print(f\"[ply_id: {ply_id}, {i + 1:5d}] loss: {running_loss / log_steps:.3f}\")\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    net.eval()\n",
    "    eval_loss, eval_f1 = evaluate(net, eval_dataloader, criterion)\n",
    "    net.train()\n",
    "    \n",
    "    print(f\"[ply_id: 66, eval] loss: {eval_loss:.3f} f1:  {eval_f1:.3f}\")\n",
    "    \n",
    "    losses.append(mean.compute())    \n",
    "    eval_losses.append(eval_loss)\n",
    "    eval_f1s.append(eval_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed84825",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "ax.plot(losses, label=\"train\")\n",
    "ax.plot(eval_losses, label=\"eval\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Loss Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d47feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "ax.plot(eval_f1s, label=\"eval\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"F1 Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a8cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
